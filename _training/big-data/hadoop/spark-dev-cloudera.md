---
title: Spark with Hadoop for Cloudera developers
sub-header: "Official training: \"Cloudera Developer Training for Spark and Hadoop\""
duration_days: 4
duration_hours: 28
time_shares:
- label: Presentation
  value: 40
- label: Use cases
  value: 50
- label: Sharing experiences
  value: 10
type: Workshop
category: hadoop
layout: training
best: true
---

### DESCRIPTION
Apache Spark has established itself in recent years as THE reference Big Data framework, and as a central tool of the Hadoop ecosystem. This intensive training takes the participant from the discovery of Spark to the use of its advanced features. 
The pedagogical approach balances theoretical contributions on the fundamental Spark structures (RDD, DataFrame, DataSets) and numerous practical works. Participants manipulate the interactive console to prototype. They then encode, deploy and monitor applications on a cluster. The program integrates the major evolutions of the new Spark 2 version, and the complex use of streaming applications. 


During the training, a panorama of the Hadoop ecosystem is drawn up, emphasizing the essential concepts of distributed environments: storage on HDFS, computing with Map-Reduce and resource management via YARN. 

Data ingestion supplements with Sqoop and Kafka are proposed, so that the participants master all the tools necessary to develop Spark applications. They thus have a complete expertise to prepare massive data and analyze it on a Hadoop cluster. 

[![Cloudera-logo](//d1ri137x9edlub.cloudfront.net/uploads/training_partner/logo/4/large_cloudera_logo_authorized_training_partner_2c.jpg)](https://www.cloudera.com/)

### PEDAGOGICAL OBJECTIVES
* Identify and use appropriate tools for each situation in a Hadoop ecosystem
* Using Apache Spark and integrating it into the Hadoop ecosystem
* Use Sqoop, Kafka, Flume, Hive and Impala

### TARGET
* Developer
* Analyst

### PRE-REQUISITES
* Be comfortable programming in one of these languages: Scala and/or Python.
* Basic knowledge of Linux command lines required.
* The basic knowledge of SQL is a plus.
* No previous experience with Hadoop is required.

### PEDAGOGICAL METHOD
Training with theoretical contributions, dialogue with participants tailored around their individual experience and feedback from the trainer's practical experience, supplemented by practical work and situation studies. Apache Spark examples and hands-on exercises are presented with Scala and Python.

Following the training, trainees will have the opportunity to take the "CCA Spark and Hadoop Developer" certification exam in Cloudera.

### STAKEHOLDER PROFILES
All our training courses are run by experienced and peer-recognized training consultants.

### EVALUATION METHODS
The evaluation of learning outcomes is carried out throughout the session through workshops and practical exercises. A warm evaluation is systematically carried out at the end of the session.